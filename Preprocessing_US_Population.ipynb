{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820ba00b",
   "metadata": {},
   "source": [
    "# US Population Data Exploration and Preprocessing\n",
    "\n",
    "This notebook explores the US Population data and prepares it for analysis.\n",
    "\n",
    "## Goals:\n",
    "1. Load and examine the population data\n",
    "2. Understand the data structure and coverage\n",
    "3. Clean up and filter the dataset\n",
    "4. Prepare data for merging with other datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb3bde",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88e44d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Display options configured for Excel-like table view\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "# Configure pandas display options for better table viewing\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', 100)      # Show up to 100 rows\n",
    "pd.set_option('display.width', None)        # Auto-detect width\n",
    "pd.set_option('display.max_colwidth', None) # Show full column content\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)  # Format floats\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Display options configured for Excel-like table view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be0bd6",
   "metadata": {},
   "source": [
    "## Step 2: Locate and Examine Population File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b44d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for population data files (.gz)...\n",
      "============================================================\n",
      "No population .gz files found with 'population' or 'pop' in name.\n",
      "\n",
      "All .gz files in workspace:\n",
      "  us.1969_2023.singleages.through89.90plus.adjusted.txt.gz (278,134,338 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Search for population .gz files in the workspace\n",
    "import glob\n",
    "\n",
    "print(\"Searching for population data files (.gz)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Look for gz files that might contain population data\n",
    "gz_files = glob.glob('**/*.gz', recursive=True)\n",
    "\n",
    "# Filter for likely population files\n",
    "pop_files = [f for f in gz_files if 'population' in f.lower() or 'pop' in f.lower()]\n",
    "\n",
    "if pop_files:\n",
    "    print(\"Population files found:\")\n",
    "    for file in pop_files:\n",
    "        file_size = os.path.getsize(file)\n",
    "        print(f\"  {file} ({file_size:,} bytes)\")\n",
    "else:\n",
    "    print(\"No population .gz files found with 'population' or 'pop' in name.\")\n",
    "    print(\"\\nAll .gz files in workspace:\")\n",
    "    for file in gz_files[:10]:  # Show first 10\n",
    "        file_size = os.path.getsize(file)\n",
    "        print(f\"  {file} ({file_size:,} bytes)\")\n",
    "    if len(gz_files) > 10:\n",
    "        print(f\"  ... and {len(gz_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e739915",
   "metadata": {},
   "source": [
    "## Step 3: Preview Population Data (from .gz file)\n",
    "\n",
    "**Note:** Update the `pop_file_path` variable below with the actual path to your population .gz file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3522df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: us.1969_2023.singleages.through89.90plus.adjusted.txt.gz\n",
      "============================================================\n",
      "First 15 lines of the file:\n",
      "1969AL01001  1910000000159\n",
      "1969AL01001  1910100000159\n",
      "1969AL01001  1910200000165\n",
      "1969AL01001  1910300000159\n",
      "1969AL01001  1910400000174\n",
      "1969AL01001  1910500000234\n",
      "1969AL01001  1910600000222\n",
      "1969AL01001  1910700000208\n",
      "1969AL01001  1910800000220\n",
      "1969AL01001  1910900000253\n",
      "1969AL01001  1911000000204\n",
      "1969AL01001  1911100000215\n",
      "1969AL01001  1911200000179\n",
      "1969AL01001  1911300000179\n",
      "1969AL01001  1911400000179\n"
     ]
    }
   ],
   "source": [
    "# Use the population file found in the workspace\n",
    "pop_file_path = 'us.1969_2023.singleages.through89.90plus.adjusted.txt.gz'\n",
    "\n",
    "# Check if file exists\n",
    "if os.path.exists(pop_file_path):\n",
    "    print(f\"Reading data from: {pop_file_path}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Read first few lines from gzip file to understand structure\n",
    "    with gzip.open(pop_file_path, 'rt') as f:\n",
    "        print(\"First 15 lines of the file:\")\n",
    "        for i, line in enumerate(f):\n",
    "            if i < 15:\n",
    "                print(line.rstrip())\n",
    "            else:\n",
    "                break\n",
    "else:\n",
    "    print(f\"File not found: {pop_file_path}\")\n",
    "    print(\"Please check the file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6da842",
   "metadata": {},
   "source": [
    "## Step 4: Load and Examine Population Data\n",
    "\n",
    "**Note:** Adjust the `sep` parameter based on the file format discovered in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78cfe8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAMPLE of population data (100,000 rows)...\n",
      "============================================================\n",
      "Sample loaded successfully!\n",
      "\n",
      "Dataset Shape: 100,000 rows × 8 columns\n",
      "\n",
      "============================================================\n",
      "DATASET INFO:\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   year         100000 non-null  int64  \n",
      " 1   state_fips   100000 non-null  object \n",
      " 2   county_fips  100000 non-null  int64  \n",
      " 3   race         0 non-null       float64\n",
      " 4   hispanic     0 non-null       float64\n",
      " 5   sex          100000 non-null  int64  \n",
      " 6   age          100000 non-null  int64  \n",
      " 7   population   100000 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(1)\n",
      "memory usage: 6.1+ MB\n",
      "\n",
      "============================================================\n",
      "First few rows:\n",
      "============================================================\n",
      "Sample loaded successfully!\n",
      "\n",
      "Dataset Shape: 100,000 rows × 8 columns\n",
      "\n",
      "============================================================\n",
      "DATASET INFO:\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   year         100000 non-null  int64  \n",
      " 1   state_fips   100000 non-null  object \n",
      " 2   county_fips  100000 non-null  int64  \n",
      " 3   race         0 non-null       float64\n",
      " 4   hispanic     0 non-null       float64\n",
      " 5   sex          100000 non-null  int64  \n",
      " 6   age          100000 non-null  int64  \n",
      " 7   population   100000 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(1)\n",
      "memory usage: 6.1+ MB\n",
      "\n",
      "============================================================\n",
      "First few rows:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "state_fips",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "county_fips",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "race",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hispanic",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "population",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a44ea19a-b08f-4ef4-98eb-4562cccc8a06",
       "rows": [
        [
         "0",
         "1969",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "15"
        ],
        [
         "1",
         "1969",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "10000015"
        ],
        [
         "2",
         "1969",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "20000016"
        ],
        [
         "3",
         "1969",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "30000015"
        ],
        [
         "4",
         "1969",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "40000017"
        ],
        [
         "5",
         "1969",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "50000023"
        ],
        [
         "6",
         "1969",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "60000022"
        ],
        [
         "7",
         "1969",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "70000020"
        ],
        [
         "8",
         "1969",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "80000022"
        ],
        [
         "9",
         "1969",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "90000025"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>race</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1969</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1969</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>10000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>20000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1969</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>30000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1969</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>40000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1969</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>50000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1969</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>60000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1969</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>70000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1969</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>80000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1969</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>90000025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year state_fips  county_fips  race  hispanic  sex  age  population\n",
       "0  1969         AL         1001   NaN       NaN    1  910          15\n",
       "1  1969         AL         1001   NaN       NaN    1  910    10000015\n",
       "2  1969         AL         1001   NaN       NaN    1  910    20000016\n",
       "3  1969         AL         1001   NaN       NaN    1  910    30000015\n",
       "4  1969         AL         1001   NaN       NaN    1  910    40000017\n",
       "5  1969         AL         1001   NaN       NaN    1  910    50000023\n",
       "6  1969         AL         1001   NaN       NaN    1  910    60000022\n",
       "7  1969         AL         1001   NaN       NaN    1  910    70000020\n",
       "8  1969         AL         1001   NaN       NaN    1  910    80000022\n",
       "9  1969         AL         1001   NaN       NaN    1  910    90000025"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a SAMPLE of the population data first for quick exploration\n",
    "# This is much faster than loading the entire file\n",
    "print(\"Loading SAMPLE of population data (100,000 rows)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Based on the preview, the format appears to be:\n",
    "# Columns: Year (4), State (2), County (5), Race (1), Hispanic Origin (1), Sex (1), Age (3), Population (8)\n",
    "\n",
    "# Read as fixed-width format\n",
    "colspecs = [\n",
    "    (0, 4),    # year\n",
    "    (4, 6),    # state FIPS\n",
    "    (6, 11),   # county FIPS (5 digits)\n",
    "    (11, 12),  # race (1=white, 2=black, 3=AIAN, 4=Asian/PI)\n",
    "    (12, 13),  # hispanic origin (1=not hispanic, 2=hispanic)\n",
    "    (13, 14),  # sex (1=male, 2=female)\n",
    "    (14, 17),  # age (0-90+, 999=total all ages)\n",
    "    (17, 25)   # population\n",
    "]\n",
    "\n",
    "column_names = ['year', 'state_fips', 'county_fips', 'race', 'hispanic', 'sex', 'age', 'population']\n",
    "\n",
    "# Load only first 100k rows for quick exploration\n",
    "df_pop = pd.read_fwf(pop_file_path, colspecs=colspecs, names=column_names, \n",
    "                     compression='gzip', nrows=100000)\n",
    "\n",
    "print(f\"Sample loaded successfully!\")\n",
    "print(f\"\\nDataset Shape: {df_pop.shape[0]:,} rows × {df_pop.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATASET INFO:\")\n",
    "print(\"=\" * 60)\n",
    "df_pop.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"First few rows:\")\n",
    "print(\"=\" * 60)\n",
    "df_pop.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bfb28",
   "metadata": {},
   "source": [
    "## Step 5: Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "278210d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Analysis:\n",
      "============================================================\n",
      "No missing values found!\n",
      "No missing values found!\n"
     ]
    }
   ],
   "source": [
    "if 'df_pop' in locals():\n",
    "    print(\"Missing Values Analysis:\")\n",
    "    print(\"=\" * 60)\n",
    "    missing = df_pop.isnull().sum()\n",
    "    missing_pct = (missing / len(df_pop)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing_Count': missing,\n",
    "        'Missing_Percentage': missing_pct\n",
    "    })\n",
    "    missing_with_values = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "    \n",
    "    if len(missing_with_values) > 0:\n",
    "        missing_with_values\n",
    "    else:\n",
    "        print(\"No missing values found!\")\n",
    "else:\n",
    "    print(\"Please load the population data first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595bea2a",
   "metadata": {},
   "source": [
    "## Step 6: Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "797d49bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Statistics:\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if 'df_pop' in locals():\n",
    "    print(\"Basic Statistics:\")\n",
    "    print(\"=\" * 60)\n",
    "    df_pop.describe(include='all')\n",
    "else:\n",
    "    print(\"Please load the population data first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fdf60e",
   "metadata": {},
   "source": [
    "## Step 7: Data Preprocessing - Filter Years and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4825e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['1969AL01001', '1910000000159']\n",
      "\n",
      "============================================================\n",
      "Unique years in dataset:\n",
      "Year column not found. Available columns:\n",
      "['1969AL01001', '1910000000159']\n"
     ]
    }
   ],
   "source": [
    "if 'df_pop' in locals():\n",
    "    # Check what columns we have\n",
    "    print(\"Column names:\")\n",
    "    print(df_pop.columns.tolist())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Unique years in dataset:\")\n",
    "    if 'year' in df_pop.columns:\n",
    "        print(f\"Years: {sorted(df_pop['year'].unique())}\")\n",
    "    elif 'Year' in df_pop.columns:\n",
    "        print(f\"Years: {sorted(df_pop['Year'].unique())}\")\n",
    "    else:\n",
    "        print(\"Year column not found. Available columns:\")\n",
    "        print(df_pop.columns.tolist())\n",
    "else:\n",
    "    print(\"Please load the population data first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34b57e",
   "metadata": {},
   "source": [
    "## Step 8: Filter for Project Time Period (2003-2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7621946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full dataset filtered for 2003-2015...\n",
      "============================================================\n",
      "This may take 1-2 minutes as we're reading the entire file...\n",
      "  Processed 5,000,000 rows...\n",
      "  Processed 5,000,000 rows...\n",
      "  Processed 10,000,000 rows...\n",
      "  Processed 10,000,000 rows...\n",
      "  Processed 15,000,000 rows...\n",
      "  Processed 15,000,000 rows...\n",
      "  Processed 20,000,000 rows...\n",
      "  Processed 20,000,000 rows...\n",
      "  Processed 25,000,000 rows...\n",
      "  Processed 25,000,000 rows...\n",
      "  Processed 30,000,000 rows...\n",
      "  Processed 30,000,000 rows...\n",
      "  Processed 35,000,000 rows...\n",
      "  Processed 35,000,000 rows...\n",
      "  Processed 40,000,000 rows...\n",
      "  Processed 40,000,000 rows...\n",
      "  Processed 45,000,000 rows...\n",
      "  Processed 45,000,000 rows...\n",
      "  Processed 50,000,000 rows...\n",
      "  Processed 50,000,000 rows...\n",
      "  Processed 55,000,000 rows...\n",
      "  Processed 55,000,000 rows...\n",
      "  Processed 60,000,000 rows...\n",
      "  Processed 60,000,000 rows...\n",
      "  Processed 65,000,000 rows...\n",
      "  Processed 65,000,000 rows...\n",
      "\n",
      "✓ Filtered dataset loaded!\n",
      "Rows (2003-2015 only): 17,620,800\n",
      "\n",
      "============================================================\n",
      "Years in filtered dataset:\n",
      "\n",
      "✓ Filtered dataset loaded!\n",
      "Rows (2003-2015 only): 17,620,800\n",
      "\n",
      "============================================================\n",
      "Years in filtered dataset:\n",
      "[np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015)]\n",
      "\n",
      "============================================================\n",
      "Sample of filtered data:\n",
      "[np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015)]\n",
      "\n",
      "============================================================\n",
      "Sample of filtered data:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "state_fips",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "county_fips",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "race",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hispanic",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "population",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d63bcc45-e1e4-4e52-8f84-d987760fa1be",
       "rows": [
        [
         "0",
         "2003",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "24"
        ],
        [
         "1",
         "2003",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "10000021"
        ],
        [
         "2",
         "2003",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "20000024"
        ],
        [
         "3",
         "2003",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "30000024"
        ],
        [
         "4",
         "2003",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "40000022"
        ],
        [
         "5",
         "2003",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "50000025"
        ],
        [
         "6",
         "2003",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "60000030"
        ],
        [
         "7",
         "2003",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "70000025"
        ],
        [
         "8",
         "2003",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "80000030"
        ],
        [
         "9",
         "2003",
         "AL",
         "1001",
         null,
         null,
         "1",
         "910",
         "90000030"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>race</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>10000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>20000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>30000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>40000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>50000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2003</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>60000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>70000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2003</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>80000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003</td>\n",
       "      <td>AL</td>\n",
       "      <td>1001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "      <td>90000030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year state_fips  county_fips  race  hispanic  sex  age  population\n",
       "0  2003         AL         1001   NaN       NaN    1  910          24\n",
       "1  2003         AL         1001   NaN       NaN    1  910    10000021\n",
       "2  2003         AL         1001   NaN       NaN    1  910    20000024\n",
       "3  2003         AL         1001   NaN       NaN    1  910    30000024\n",
       "4  2003         AL         1001   NaN       NaN    1  910    40000022\n",
       "5  2003         AL         1001   NaN       NaN    1  910    50000025\n",
       "6  2003         AL         1001   NaN       NaN    1  910    60000030\n",
       "7  2003         AL         1001   NaN       NaN    1  910    70000025\n",
       "8  2003         AL         1001   NaN       NaN    1  910    80000030\n",
       "9  2003         AL         1001   NaN       NaN    1  910    90000030"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now load ONLY the years we need (2003-2015) from the full file\n",
    "# This is more efficient than loading all years then filtering\n",
    "print(\"Loading full dataset filtered for 2003-2015...\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This may take 1-2 minutes as we're reading the entire file...\")\n",
    "\n",
    "# Define a function to filter as we read\n",
    "def year_filter(df_chunk):\n",
    "    return df_chunk[(df_chunk['year'] >= 2003) & (df_chunk['year'] <= 2015)]\n",
    "\n",
    "# Read the file in chunks and filter\n",
    "chunks = []\n",
    "chunk_size = 500000  # Read 500k rows at a time\n",
    "\n",
    "reader = pd.read_fwf(pop_file_path, colspecs=colspecs, names=column_names, \n",
    "                     compression='gzip', chunksize=chunk_size)\n",
    "\n",
    "for i, chunk in enumerate(reader):\n",
    "    # Filter this chunk\n",
    "    filtered_chunk = year_filter(chunk)\n",
    "    if not filtered_chunk.empty:\n",
    "        chunks.append(filtered_chunk)\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Processed {(i + 1) * chunk_size:,} rows...\")\n",
    "\n",
    "# Combine all filtered chunks\n",
    "df_pop_filtered = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "print(f\"\\n✓ Filtered dataset loaded!\")\n",
    "print(f\"Rows (2003-2015 only): {df_pop_filtered.shape[0]:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Years in filtered dataset:\")\n",
    "print(sorted(df_pop_filtered['year'].unique()))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Sample of filtered data:\")\n",
    "df_pop_filtered.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d639d8f",
   "metadata": {},
   "source": [
    "## Step 9: Save Filtered Data to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12a5e6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered data to: us_population_2003_2015_filtered.parquet\n",
      "============================================================\n",
      "✓ Filtered data saved successfully!\n",
      "  File size: 23,849,744 bytes (22.74 MB)\n",
      "  Rows: 17,620,800\n",
      "  Columns: 8\n",
      "\n",
      "============================================================\n",
      "From now on, we'll work with the Parquet file for faster processing.\n",
      "✓ Filtered data saved successfully!\n",
      "  File size: 23,849,744 bytes (22.74 MB)\n",
      "  Rows: 17,620,800\n",
      "  Columns: 8\n",
      "\n",
      "============================================================\n",
      "From now on, we'll work with the Parquet file for faster processing.\n"
     ]
    }
   ],
   "source": [
    "if 'df_pop_filtered' in locals():\n",
    "    # Save the filtered data to parquet for efficient subsequent processing\n",
    "    filtered_file = 'us_population_2003_2015_filtered.parquet'\n",
    "    \n",
    "    print(f\"Saving filtered data to: {filtered_file}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df_pop_filtered.to_parquet(filtered_file, index=False, compression='snappy')\n",
    "    \n",
    "    # Check file size\n",
    "    file_size = os.path.getsize(filtered_file)\n",
    "    print(f\"✓ Filtered data saved successfully!\")\n",
    "    print(f\"  File size: {file_size:,} bytes ({file_size / (1024**2):.2f} MB)\")\n",
    "    print(f\"  Rows: {df_pop_filtered.shape[0]:,}\")\n",
    "    print(f\"  Columns: {df_pop_filtered.shape[1]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"From now on, we'll work with the Parquet file for faster processing.\")\n",
    "else:\n",
    "    print(\"Please filter the data first (run Step 8).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef26141",
   "metadata": {},
   "source": [
    "## Step 10: Load from Parquet and Aggregate by State and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c737c403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading filtered data from Parquet: us_population_2003_2015_filtered.parquet\n",
      "============================================================\n",
      "✓ Data loaded from Parquet!\n",
      "  Rows: 17,620,800\n",
      "  Columns: 8\n",
      "\n",
      "============================================================\n",
      "Aggregating by state and year...\n",
      "============================================================\n",
      "✓ Data loaded from Parquet!\n",
      "  Rows: 17,620,800\n",
      "  Columns: 8\n",
      "\n",
      "============================================================\n",
      "Aggregating by state and year...\n",
      "============================================================\n",
      "\n",
      "✓ Aggregated dataset created!\n",
      "  Shape: 664 rows × 3 columns\n",
      "\n",
      "============================================================\n",
      "Sample of aggregated data:\n",
      "\n",
      "✓ Aggregated dataset created!\n",
      "  Shape: 664 rows × 3 columns\n",
      "\n",
      "============================================================\n",
      "Sample of aggregated data:\n"
     ]
    }
   ],
   "source": [
    "# Load the filtered data from Parquet (much faster than CSV/TSV!)\n",
    "filtered_file = 'us_population_2003_2015_filtered.parquet'\n",
    "\n",
    "if os.path.exists(filtered_file):\n",
    "    print(f\"Loading filtered data from Parquet: {filtered_file}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load from parquet - very fast!\n",
    "    df_pop_filtered = pd.read_parquet(filtered_file)\n",
    "    \n",
    "    print(f\"✓ Data loaded from Parquet!\")\n",
    "    print(f\"  Rows: {df_pop_filtered.shape[0]:,}\")\n",
    "    print(f\"  Columns: {df_pop_filtered.shape[1]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Aggregating by state and year...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Aggregate population by state and year (sum across counties, age, sex, race, hispanic origin)\n",
    "    df_pop_agg = df_pop_filtered.groupby(['state_fips', 'year'])['population'].sum().reset_index()\n",
    "    \n",
    "    print(f\"\\n✓ Aggregated dataset created!\")\n",
    "    print(f\"  Shape: {df_pop_agg.shape[0]:,} rows × {df_pop_agg.shape[1]} columns\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Sample of aggregated data:\")\n",
    "    df_pop_agg.head(20)\n",
    "else:\n",
    "    print(f\"File not found: {filtered_file}\")\n",
    "    print(\"Please run Step 9 first to create the filtered Parquet file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e80815",
   "metadata": {},
   "source": [
    "## Step 11: Save Final Aggregated Data to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86a15b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed population data to: us_population_2003_2015.parquet\n",
      "============================================================\n",
      "✓ File saved successfully!\n",
      "  File size: 8,763 bytes (8.56 KB)\n",
      "  Rows: 664\n",
      "  Columns: 3\n",
      "\n",
      "============================================================\n",
      "Summary of processed data:\n",
      "  Years covered: 2003 - 2015\n",
      "  Number of states/regions: 52\n",
      "  Total population records: 664\n"
     ]
    }
   ],
   "source": [
    "if 'df_pop_agg' in locals():\n",
    "    # Save to parquet format for efficient storage and fast loading\n",
    "    output_file = 'us_population_2003_2015.parquet'\n",
    "    \n",
    "    print(f\"Saving processed population data to: {output_file}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df_pop_agg.to_parquet(output_file, index=False, compression='snappy')\n",
    "    \n",
    "    # Check file size\n",
    "    file_size = os.path.getsize(output_file)\n",
    "    print(f\"✓ File saved successfully!\")\n",
    "    print(f\"  File size: {file_size:,} bytes ({file_size / 1024:.2f} KB)\")\n",
    "    print(f\"  Rows: {df_pop_agg.shape[0]:,}\")\n",
    "    print(f\"  Columns: {df_pop_agg.shape[1]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Summary of processed data:\")\n",
    "    print(f\"  Years covered: {df_pop_agg['year'].min()} - {df_pop_agg['year'].max()}\")\n",
    "    print(f\"  Number of states/regions: {df_pop_agg['state_fips'].nunique()}\")\n",
    "    print(f\"  Total population records: {df_pop_agg.shape[0]:,}\")\n",
    "else:\n",
    "    print(\"Please create the aggregated dataset first (run Step 10).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
