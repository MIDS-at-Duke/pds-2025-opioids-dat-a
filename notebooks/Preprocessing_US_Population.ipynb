{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820ba00b",
   "metadata": {},
   "source": [
    "# US Population Data Exploration and Preprocessing (SEER Format)\n",
    "\n",
    "This notebook explores the US Population data in **SEER fixed-width format** and prepares it for analysis.\n",
    "\n",
    "## SEER Fixed-Width Format Specification:\n",
    "\n",
    "**File Format:** Fixed length ASCII text (26 bytes per record)\n",
    "\n",
    "| Variable | Start Column | Length | Type | Description |\n",
    "|----------|--------------|--------|------|-------------|\n",
    "| Year | 1 | 4 | numeric | 1969, 1970, ... 2023 |\n",
    "| State Abbrev | 5 | 2 | character | AL, AK, ... (KR for Katrina evacuees) |\n",
    "| State FIPS | 7 | 2 | numeric | 01, 02, ... (99 for dummy state) |\n",
    "| County FIPS | 9 | 3 | numeric | 001, 002, ... (999 for dummy) |\n",
    "| Race | 14 | 1 | numeric | 1=White, 2=Black, 3=AIAN, 4=API |\n",
    "| Origin | 15 | 1 | numeric | 0=Non-Hispanic, 1=Hispanic, 9=N/A |\n",
    "| Sex | 16 | 1 | numeric | 1=Male, 2=Female |\n",
    "| Age | 17 | 2 | numeric | 00-90 (single year), 90=90+ |\n",
    "| Population | 19 | 8 | numeric | Population count |\n",
    "\n",
    "**Example:** `1969AL01001112000000159`\n",
    "- 1969 = Year\n",
    "- AL = Alabama\n",
    "- 01 = State FIPS\n",
    "- 001 = County code\n",
    "- 1 = White\n",
    "- 1 = Hispanic\n",
    "- 2 = Female\n",
    "- 00 = Age 0\n",
    "- 00000159 = Population\n",
    "\n",
    "## Goals:\n",
    "1. Parse SEER fixed-width format correctly\n",
    "2. Extract state and county FIPS codes (create 5-digit FIPS)\n",
    "3. Filter for 2006-2015 (to match ARCOS prescription data)\n",
    "4. Aggregate by county-year (sum across race, origin, sex, age)\n",
    "5. Create county-year dataset for merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb3bde",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88e44d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Display options configured for Excel-like table view\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "# Configure pandas display options for better table viewing\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', 100)      # Show up to 100 rows\n",
    "pd.set_option('display.width', None)        # Auto-detect width\n",
    "pd.set_option('display.max_colwidth', None) # Show full column content\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)  # Format floats\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(\"Display options configured for Excel-like table view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be0bd6",
   "metadata": {},
   "source": [
    "## Step 2: Locate and Examine Population File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09b44d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for population data files (.gz)...\n",
      "============================================================\n",
      "No population .gz files found with 'population' or 'pop' in name.\n",
      "\n",
      "All .gz files in workspace:\n"
     ]
    }
   ],
   "source": [
    "# Search for population .gz files in the workspace\n",
    "import glob\n",
    "\n",
    "print(\"Searching for population data files (.gz)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Look for gz files that might contain population data\n",
    "gz_files = glob.glob('**/*.gz', recursive=True)\n",
    "\n",
    "# Filter for likely population files\n",
    "pop_files = [f for f in gz_files if 'population' in f.lower() or 'pop' in f.lower()]\n",
    "\n",
    "if pop_files:\n",
    "    print(\"Population files found:\")\n",
    "    for file in pop_files:\n",
    "        file_size = os.path.getsize(file)\n",
    "        print(f\"  {file} ({file_size:,} bytes)\")\n",
    "else:\n",
    "    print(\"No population .gz files found with 'population' or 'pop' in name.\")\n",
    "    print(\"\\nAll .gz files in workspace:\")\n",
    "    for file in gz_files[:10]:  # Show first 10\n",
    "        file_size = os.path.getsize(file)\n",
    "        print(f\"  {file} ({file_size:,} bytes)\")\n",
    "    if len(gz_files) > 10:\n",
    "        print(f\"  ... and {len(gz_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e739915",
   "metadata": {},
   "source": [
    "## Step 3: Preview Population Data (from .gz file)\n",
    "\n",
    "**Note:** Update the `pop_file_path` variable below with the actual path to your population .gz file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3522df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: ../data/raw/us.1969_2023.singleages.through89.90plus.adjusted.txt.gz\n",
      "============================================================\n",
      "First 20 lines of the file (SEER fixed-width format):\n",
      "\n",
      "Position:   0         1         2\n",
      "            0123456789012345678901234\n",
      "Line  1: [1969AL01001  1910000000159]\n",
      "Line  2: [1969AL01001  1910100000159]\n",
      "Line  3: [1969AL01001  1910200000165]\n",
      "Line  4: [1969AL01001  1910300000159]\n",
      "Line  5: [1969AL01001  1910400000174]\n",
      "Line  6: [1969AL01001  1910500000234]\n",
      "Line  7: [1969AL01001  1910600000222]\n",
      "Line  8: [1969AL01001  1910700000208]\n",
      "Line  9: [1969AL01001  1910800000220]\n",
      "Line 10: [1969AL01001  1910900000253]\n",
      "Line 11: [1969AL01001  1911000000204]\n",
      "Line 12: [1969AL01001  1911100000215]\n",
      "Line 13: [1969AL01001  1911200000179]\n",
      "Line 14: [1969AL01001  1911300000179]\n",
      "Line 15: [1969AL01001  1911400000179]\n",
      "Line 16: [1969AL01001  1911500000171]\n",
      "Line 17: [1969AL01001  1911600000165]\n",
      "Line 18: [1969AL01001  1911700000164]\n",
      "Line 19: [1969AL01001  1911800000123]\n",
      "Line 20: [1969AL01001  1911900000098]\n",
      "\n",
      "============================================================\n",
      "Format breakdown:\n",
      "Columns 0-10:   Geographic ID (1969 + State + Level + County)\n",
      "Columns 11-23:  Year-Population (191 + YearCode + Population)\n"
     ]
    }
   ],
   "source": [
    "# Use the population file in data/raw/\n",
    "pop_file_path = '../data/raw/us.1969_2023.singleages.through89.90plus.adjusted.txt.gz'\n",
    "\n",
    "# Check if file exists\n",
    "if os.path.exists(pop_file_path):\n",
    "    print(f\"Reading data from: {pop_file_path}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Read first few lines from gzip file to understand structure\n",
    "    with gzip.open(pop_file_path, 'rt') as f:\n",
    "        print(\"First 20 lines of the file (SEER fixed-width format):\")\n",
    "        print()\n",
    "        for i, line in enumerate(f):\n",
    "            if i < 20:\n",
    "                # Show the line with position markers\n",
    "                if i == 0:\n",
    "                    print(\"Position:   0         1         2\")\n",
    "                    print(\"            0123456789012345678901234\")\n",
    "                print(f\"Line {i+1:2d}: [{line.rstrip()}]\")\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Format breakdown:\")\n",
    "    print(\"Columns 0-10:   Geographic ID (1969 + State + Level + County)\")\n",
    "    print(\"Columns 11-23:  Year-Population (191 + YearCode + Population)\")\n",
    "else:\n",
    "    print(f\"File not found: {pop_file_path}\")\n",
    "    print(\"Please check the file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6da842",
   "metadata": {},
   "source": [
    "## Step 4: Parse SEER Fixed-Width Format\n",
    "\n",
    "Now we'll correctly parse the SEER format:\n",
    "- Extract state and county FIPS codes from column 1\n",
    "- Decode year from year code in column 2\n",
    "- Extract population from column 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78cfe8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing SEER fixed-width format...\n",
      "============================================================\n",
      "Testing parser on first 10 lines:\n",
      "--------------------------------------------------------------------------------\n",
      "Line 1: Year=1969, State=AL, FIPS=01001, Age=00, Pop=159\n",
      "Line 2: Year=1969, State=AL, FIPS=01001, Age=01, Pop=159\n",
      "Line 3: Year=1969, State=AL, FIPS=01001, Age=02, Pop=165\n",
      "Line 4: Year=1969, State=AL, FIPS=01001, Age=03, Pop=159\n",
      "Line 5: Year=1969, State=AL, FIPS=01001, Age=04, Pop=174\n",
      "Line 6: Year=1969, State=AL, FIPS=01001, Age=05, Pop=234\n",
      "Line 7: Year=1969, State=AL, FIPS=01001, Age=06, Pop=222\n",
      "Line 8: Year=1969, State=AL, FIPS=01001, Age=07, Pop=208\n",
      "Line 9: Year=1969, State=AL, FIPS=01001, Age=08, Pop=220\n",
      "Line 10: Year=1969, State=AL, FIPS=01001, Age=09, Pop=253\n",
      "\n",
      "✓ Parser working correctly!\n"
     ]
    }
   ],
   "source": [
    "print(\"Parsing SEER fixed-width format...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def parse_seer_line(line):\n",
    "    \"\"\"\n",
    "    Parse a line in SEER fixed-width format (26 bytes).\n",
    "    \n",
    "    Format (1-indexed in docs, 0-indexed in Python):\n",
    "    Column  1-4  (0:4):   Year (1969-2023)\n",
    "    Column  5-6  (4:6):   State abbreviation (AL, AK, etc.)\n",
    "    Column  7-8  (6:8):   State FIPS code (01, 02, etc.)\n",
    "    Column  9-11 (8:11):  County FIPS code (001, 002, etc.)\n",
    "    Column  14   (13):    Race (1=White, 2=Black, 3=AIAN, 4=API)\n",
    "    Column  15   (14):    Origin (0=Non-Hispanic, 1=Hispanic, 9=N/A)\n",
    "    Column  16   (15):    Sex (1=Male, 2=Female)\n",
    "    Column  17-18 (16:18): Age (00-90, 90=90+)\n",
    "    Column  19-26 (18:26): Population (8 digits)\n",
    "    \n",
    "    Example: \"1969AL01001112000000159\"\n",
    "    \"\"\"\n",
    "    if len(line) < 26:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Extract fields (using 0-indexed positions)\n",
    "        year = int(line[0:4])\n",
    "        state_abbrev = line[4:6]\n",
    "        state_fips = line[6:8]\n",
    "        county_code = line[8:11]\n",
    "        race = line[13]\n",
    "        origin = line[14]\n",
    "        sex = line[15]\n",
    "        age = line[16:18]\n",
    "        population_str = line[18:26]\n",
    "        \n",
    "        # Create 5-digit FIPS: state + county\n",
    "        fips = state_fips + county_code\n",
    "        \n",
    "        # Parse population\n",
    "        pop = int(population_str)\n",
    "        \n",
    "        return {\n",
    "            'year': year,\n",
    "            'state_abbrev': state_abbrev,\n",
    "            'state_fips': state_fips,\n",
    "            'county_code': county_code,\n",
    "            'fips': fips,\n",
    "            'race': race,\n",
    "            'origin': origin,\n",
    "            'sex': sex,\n",
    "            'age': age,\n",
    "            'population': pop\n",
    "        }\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "\n",
    "# Test the parser on first 10 lines\n",
    "print(\"Testing parser on first 10 lines:\")\n",
    "print(\"-\" * 80)\n",
    "with gzip.open(pop_file_path, 'rt') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i < 10:\n",
    "            result = parse_seer_line(line.rstrip())\n",
    "            if result:\n",
    "                print(f\"Line {i+1}: Year={result['year']}, State={result['state_abbrev']}, \"\n",
    "                      f\"FIPS={result['fips']}, Age={result['age']}, Pop={result['population']:,}\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "print(\"\\n✓ Parser working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4496ee52",
   "metadata": {},
   "source": [
    "## Step 5: Load and Parse Dataset (2006-2015)\n",
    "\n",
    "Load and parse the dataset, filtering for years 2006-2015 only to match the ARCOS prescription data timeframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509bfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and parsing full dataset (all years 1969-2023)...\n",
      "============================================================\n",
      "Processing file and creating aggregated data directly...\n",
      "This approach sums population as we parse to save memory.\n",
      "\n",
      "  Processed 10,000,000 lines, tracking 28,417 unique county-years\n",
      "  Processed 10,000,000 lines, tracking 28,417 unique county-years\n",
      "  Processed 20,000,000 lines, tracking 55,298 unique county-years\n",
      "  Processed 20,000,000 lines, tracking 55,298 unique county-years\n",
      "  Processed 30,000,000 lines, tracking 82,404 unique county-years\n",
      "  Processed 30,000,000 lines, tracking 82,404 unique county-years\n",
      "  Processed 40,000,000 lines, tracking 108,308 unique county-years\n",
      "  Processed 40,000,000 lines, tracking 108,308 unique county-years\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m line_count = \u001b[32m0\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m gzip.open(pop_file_path, \u001b[33m'\u001b[39m\u001b[33mrt\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mline_count\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Parse the line\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\miniforge3\\Lib\\gzip.py:351\u001b[39m, in \u001b[36mGzipFile.read1\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size < \u001b[32m0\u001b[39m:\n\u001b[32m    350\u001b[39m     size = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\miniforge3\\Lib\\_compression.py:68\u001b[39m, in \u001b[36mDecompressReader.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view.cast(\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] = data\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\miniforge3\\Lib\\gzip.py:567\u001b[39m, in \u001b[36m_GzipReader.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buf == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    564\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCompressed file ended before the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    565\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mend-of-stream marker was reached\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m \u001b[38;5;28mself\u001b[39m._crc = \u001b[43mzlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcrc32\u001b[49m\u001b[43m(\u001b[49m\u001b[43muncompress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_crc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[38;5;28mself\u001b[39m._stream_size += \u001b[38;5;28mlen\u001b[39m(uncompress)\n\u001b[32m    569\u001b[39m \u001b[38;5;28mself\u001b[39m._pos += \u001b[38;5;28mlen\u001b[39m(uncompress)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"Loading and parsing dataset (filtering for 2006-2015)...\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Processing file and creating aggregated data directly...\")\n",
    "print(\"This approach sums population as we parse to save memory.\")\n",
    "print()\n",
    "\n",
    "# Create a dictionary to aggregate as we parse\n",
    "# Key: (year, fips, state_abbrev, state_fips, county_code)\n",
    "# Value: total_population\n",
    "population_dict = {}\n",
    "line_count = 0\n",
    "filtered_count = 0\n",
    "\n",
    "with gzip.open(pop_file_path, 'rt') as f:\n",
    "    for line in f:\n",
    "        line_count += 1\n",
    "        \n",
    "        # Parse the line\n",
    "        result = parse_seer_line(line.rstrip())\n",
    "        \n",
    "        if result and 2006 <= result['year'] <= 2015:\n",
    "            filtered_count += 1\n",
    "            \n",
    "            # Create key for aggregation\n",
    "            key = (\n",
    "                result['year'],\n",
    "                result['fips'],\n",
    "                result['state_abbrev'],\n",
    "                result['state_fips'],\n",
    "                result['county_code']\n",
    "            )\n",
    "            \n",
    "            # Sum population for this key\n",
    "            if key in population_dict:\n",
    "                population_dict[key] += result['population']\n",
    "            else:\n",
    "                population_dict[key] = result['population']\n",
    "        \n",
    "        # Progress indicator every 10 million lines\n",
    "        if line_count % 10_000_000 == 0:\n",
    "            print(f\"  Processed {line_count:,} lines, kept {filtered_count:,} rows, tracking {len(population_dict):,} unique county-years\")\n",
    "\n",
    "print(f\"\\n✓ Parsing and aggregation complete!\")\n",
    "print(f\"  Total lines processed: {line_count:,}\")\n",
    "print(f\"  Rows kept (2006-2015): {filtered_count:,}\")\n",
    "print(f\"  Unique county-year combinations: {len(population_dict):,}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "print(\"\\nConverting to DataFrame...\")\n",
    "df_pop_condensed = pd.DataFrame([\n",
    "    {\n",
    "        'year': key[0],\n",
    "        'fips': key[1],\n",
    "        'state_abbrev': key[2],\n",
    "        'state_fips': key[3],\n",
    "        'county_code': key[4],\n",
    "        'population': value\n",
    "    }\n",
    "    for key, value in population_dict.items()\n",
    "])\n",
    "\n",
    "# Sort for better organization\n",
    "df_pop_condensed = df_pop_condensed.sort_values(['fips', 'year']).reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ DataFrame created!\")\n",
    "print(f\"  Shape: {df_pop_condensed.shape[0]:,} rows × {df_pop_condensed.shape[1]} columns\")\n",
    "print(f\"  Columns: {df_pop_condensed.columns.tolist()}\")\n",
    "print(f\"  Year range: {df_pop_condensed['year'].min()} - {df_pop_condensed['year'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"First 20 rows:\")\n",
    "print(df_pop_condensed.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfda762",
   "metadata": {},
   "source": [
    "## Step 6: Verify Aggregated Data\n",
    "\n",
    "The data was already collapsed during parsing (Step 5) to save memory. Let's verify the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_pop_condensed' in locals():\n",
    "    print(\"Data already aggregated during parsing!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"Dataset Summary:\")\n",
    "    print(f\"  Shape: {df_pop_condensed.shape[0]:,} rows × {df_pop_condensed.shape[1]} columns\")\n",
    "    print(f\"  Years: {df_pop_condensed['year'].min()} - {df_pop_condensed['year'].max()}\")\n",
    "    print(f\"  Unique FIPS codes: {df_pop_condensed['fips'].nunique():,}\")\n",
    "    print(f\"  Columns: {df_pop_condensed.columns.tolist()}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Sample statistics:\")\n",
    "    print(df_pop_condensed.describe())\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Sample records from different years:\")\n",
    "    print(df_pop_condensed.sample(10).sort_values(['fips', 'year']))\n",
    "else:\n",
    "    print(\"Please load and aggregate the data first (run Step 5).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef7bef",
   "metadata": {},
   "source": [
    "## Step 7: Save to Parquet\n",
    "\n",
    "Save the condensed county-year population dataset to a parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0cc6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_pop_condensed' in locals():\n",
    "    # Save to parquet in data/processed/\n",
    "    output_file = '../data/processed/us_population_condensed_2006_2015.parquet'\n",
    "    \n",
    "    print(f\"Saving condensed population data to: {output_file}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df_pop_condensed.to_parquet(output_file, index=False, compression='snappy')\n",
    "    \n",
    "    # Check file size\n",
    "    file_size = os.path.getsize(output_file)\n",
    "    print(f\"✓ File saved successfully!\")\n",
    "    print(f\"  File: {output_file}\")\n",
    "    print(f\"  Size: {file_size:,} bytes ({file_size / (1024**2):.2f} MB)\")\n",
    "    print(f\"  Rows: {df_pop_condensed.shape[0]:,}\")\n",
    "    print(f\"  Columns: {df_pop_condensed.shape[1]}\")\n",
    "    print(f\"  Column names: {df_pop_condensed.columns.tolist()}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Summary:\")\n",
    "    print(f\"  Years: {df_pop_condensed['year'].min()} - {df_pop_condensed['year'].max()}\")\n",
    "    print(f\"  Counties: {df_pop_condensed['fips'].nunique():,}\")\n",
    "    print(f\"  Total records: {df_pop_condensed.shape[0]:,}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✓ Condensed population dataset ready for 2006-2015!\")\n",
    "else:\n",
    "    print(\"Please aggregate the data first (run Step 6).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
